{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60642e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRI MANASA NALLAGATLA\n",
    "# SPAM MAIL CHECK \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b596a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "dt=pd.read_csv(\"spamcheck.csv\")\n",
    "dt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6baa9531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['spam']=dt['type'].map({'spam':1,'ham':0}).astype(int)\n",
    "dt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfcdb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colums in the given data :\n",
      "type\n",
      "text\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "print(\"colums in the given data :\")\n",
    "for col in dt.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07bfda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in review column: 116\n",
      "Number of colums in liked column: 116\n"
     ]
    }
   ],
   "source": [
    "t=len(dt['type'])\n",
    "print(\"Number of rows in review column:\",t)\n",
    "t=len(dt['text'])\n",
    "print(\"Number of colums in liked column:\",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985715f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before tokenization\n",
    "dt['text'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da2a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05155fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text']=dt['text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83e3bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after tokenization\n",
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e094051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE STEMMING\n",
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6cef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter=SnowballStemmer(\"english\",ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddfd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_it(text):\n",
    "    return[porter.stem(word) for word in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f520e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text']=dt['text'].apply(stem_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4a4625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok', 'lar...', 'joke', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After Stemming\n",
    "dt['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da743752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'was',\n",
       " 'like',\n",
       " 'you',\n",
       " 'better',\n",
       " 'not',\n",
       " 'be',\n",
       " 'lying.',\n",
       " 'then',\n",
       " 'again',\n",
       " 'i',\n",
       " 'am',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LEMMITIZATION\n",
    "#before\n",
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fdbc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bcc6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmit_it(text):\n",
    "    return[lemmatizer.lemmatize(word,pos=\"a\") for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f1d9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text']=dt['text'].apply(lemmit_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22636e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'know!',\n",
       " 'grumpi',\n",
       " 'old',\n",
       " 'people.',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'was',\n",
       " 'like',\n",
       " 'you',\n",
       " 'good',\n",
       " 'not',\n",
       " 'be',\n",
       " 'lying.',\n",
       " 'then',\n",
       " 'again',\n",
       " 'i',\n",
       " 'am',\n",
       " 'alway',\n",
       " 'the',\n",
       " 'one',\n",
       " 'to',\n",
       " 'play',\n",
       " 'jokes...']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['text'][109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7a5742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nah',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'think',\n",
       " 'he',\n",
       " 'goe',\n",
       " 'to',\n",
       " 'usf,',\n",
       " 'he',\n",
       " 'live',\n",
       " 'around',\n",
       " 'here',\n",
       " 'though']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STOPWORD \n",
    "#before \n",
    "dt['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565524a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\f8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#stop_words=stopwords.words('english')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74e3ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5685e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_it(text):\n",
    "    review=[word for word in text if not word in stop_words]\n",
    "    return review\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43333b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text']=dt['text'].apply(stop_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "737166a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nah', 'think', 'goe', 'usf,', 'live', 'around', 'though']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After Stopword\n",
    "dt['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a50737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back!, i'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>[even, brother, like, speak, me., treat, like,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>[per, request, mell, mell, (oru, minnaminungin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>[winner!!, valu, network, custom, select, rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>[mobil, 11, month, more?, u, r, entitl, updat,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
       "1   ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
       "3   ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
       "4   ham      [nah, think, goe, usf,, live, around, though]     0\n",
       "5  spam  [freemsg, hey, darl, 3, week, word, back!, i'd...     1\n",
       "6   ham  [even, brother, like, speak, me., treat, like,...     0\n",
       "7   ham  [per, request, mell, mell, (oru, minnaminungin...     0\n",
       "8  spam  [winner!!, valu, network, custom, select, rece...     1\n",
       "9  spam  [mobil, 11, month, more?, u, r, entitl, updat,...     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c68d8813",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['text']=dt['text'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76b18a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea £...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1   ham                        ok lar... joke wif u oni...     0\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3   ham          u dun say earli hor... u c alreadi say...     0\n",
       "4   ham              nah think goe usf, live around though     0\n",
       "5  spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6   ham  even brother like speak me. treat like aid pat...     0\n",
       "7   ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8  spam  winner!! valu network custom select receivea £...     1\n",
       "9  spam  mobil 11 month more? u r entitl updat late col...     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1144effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM TEXT DATA INTO TDF /TF-IDF VECTORS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "y=dt.spam.values\n",
    "x=tfidf.fit_transform(dt['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a32b01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_text,y_train,y_text=train_test_split(x,y,random_state=1,test_size=0.004,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33563835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred=clf.predict(x_text)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_log=accuracy_score(y_pred,y_text)*100\n",
    "print(\"Accuracy:\",acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afad2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svc=LinearSVC(random_state=0)\n",
    "linear_svc.fit(x_train,y_train)\n",
    "y_pred=linear_svc.predict(x_text)\n",
    "acc_linear_svc=accuracy_score(y_pred,y_text)*100\n",
    "print(\"Accuracy:\",acc_linear_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
